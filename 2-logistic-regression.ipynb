{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression from scratch\n",
    "\n",
    "https://gluon.mxnet.io/chapter02_supervised-learning/logistic-regression-gluon.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid function\n",
    "\n",
    "$\\sigma(z) = \\frac{1}{1 + \\exp(-z)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic(z):\n",
    "    return 1. / (1. + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(-5, 5, .1)\n",
    "y = logistic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e8fd2fb4a8>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGxRJREFUeJzt3Xuc1XW1//HXAkTNUAQJE4SUJEkFRUSszK2UjpgXtI6g\nx9JM8YIiluIlg44iYh5N84L0U37eCk1D0TRRdLzGTQUMZ7hJ3IXwgukRGGCdPz5bzjTOMBvYe3/2\n97vfz8fj+5jZe39nz/o6zHLN+ly+5u6IiEjyNYkdgIiI5IcSuohISiihi4ikhBK6iEhKKKGLiKSE\nErqISEo0mtDN7B4zW2FmMzdzzm1mNtfMppvZgfkNUUREcpFLhT4GOKahF83sWKCTu+8DDABG5Sk2\nERHZAo0mdHd/FfhwM6ecCNyfPXcysIuZtc1PeCIikqt89NDbAYtrPV6afU5ERIpIg6IiIinRLA/v\nsRTYs9bj9tnnvsDMtHGMiMhWcHdr7JxcK3TLHvUZD/wYwMx6AR+5+4rNBJXaY+jQodFj0PXp+srt\n2nK9vnXrnEWLnMmTnfHjndGjneuucwYNck47zTn6aKd7d6djR6dFC6dpU6dVK2fvvcPzZ58d7/py\n1WiFbmZ/ADJAazNbBAwFmofc7KPd/Wkz62Nm84BPgbNy/u4iInny4Ycwfz4sWAALF4Zj8eJwLFkC\nH3wAX/kKfPWrsPvu0LZteNyxI/ToAbvtFo7WraFVK2jRApokrCndaEJ399NyOGdgfsIREWnYunUw\ndy688w5UVcGcOeGYORNuvhk6dYK99gpJulMnOPJIaN8+HG3bQtOmsa+gsPLRQ5esTCYTO4SC0vUl\nVxKv7YMP4M03wzFjRkja8+aFZN2lSzi+/3248EJYuTLDCSeANdplTjfbkv7MNn8zMy/m9xORZNiw\nISTt116DyZNh0iRYuRIOPBC6d4eDDoKuXUMS32GH2NEWn5nhOQyKKqGLSNFt3AjTp8Pzz8OLL8Lr\nr4e2yLe/Db16hWPffZPXwy4UJXQRKSmrVsFf/wrPPAPPPgtt2kDv3uE4/PAwICn1U0IXkegWL4bH\nHoNx40JFftRR0KcPVFTAnns2/vUSKKGLSBSrVsHDD8PYsWE2yoknQt++8L3vwY47xo4umZTQRaRo\nNmwIbZR77w198T594LTT4OijoXnz2NElnxK6iBTcypUhiY8aFRbpnH02nHoqtGwZO7J0yTWhax66\niGyxqqqwkOfRR+Hkk8PHHj1iRyVK6CKSs2nT4NprwzzxCy4IqzTbtIkdlXxOCV1EGjVtGgwdGhb/\nDBkSBjw1wFl6NG1fRBo0d27oiZ9wAhx3XNj86qKLlMxLlRK6iHzB6tVw6aVw2GHQrVtI7BdcANtv\nHzsy2RwldBHZZONGGDMmLLv/17/CPPKrroKddoodmeRCPXQRAWD2bDj3XFizBp58UrNWkkgVukiZ\nW78err8+bIx1yilhoywl82RShS5SxubMgR//ONyd5803oUOH2BHJtlCFLlKG3OHuu+Fb34IzzgjL\n9pXMk08VukiZ+fhjOOccqK6GV18NA6CSDqrQRcrIjBlw8MHhJsiTJimZp40qdJEy8cgj4f6bt94a\ndkKU9FFCF0m5jRvhmmvgoYdgwoRwf05JJyV0kRT77LMwi+W992DqVG2klXbqoYuk1KpV4X6dzZqF\nm04omaefErpICi1cGKYkHnFEaLVoD5byoIQukjLV1XD44TBwIIwYAU30W1421EMXSZG33gr38xwx\nAs48M3Y0UmxK6CIp8eabcOyxcOedYU8WKT9K6CIp8HllPmoU9O0bOxqJRd01kYSbOTNU5nfcoWRe\n7pTQRRJs3jyoqIDbblObRZTQRRJr2TI4+mj49a/hP/4jdjRSCpTQRRLoww/hmGPCHYbOOSd2NFIq\nzN2L983MvJjfTySN1q4Nybx7d/jv/waz2BFJoZkZ7t7oT1oJXSRB3MMNKdasCbsnatFQecg1oWva\nokiCDB0aBkJffFHJXL4op38SZlZhZtVmNsfMhtTz+s5mNt7MppvZ22Z2Zt4jFSlzf/wjPPggjB8P\nO+4YOxopRY22XMysCTAH6A0sA6YC/dy9utY5VwI7u/uVZrYbMBto6+7r67yXWi4iW+GNN8L0xIkT\noWvX2NFIseXacsmlQu8JzHX3he5eA4wFTqxzjgMtsp+3AN6vm8xFZOusWBEWDI0apWQum5dLQm8H\nLK71eEn2udpuB75pZsuAGcCg/IQnUt5qauCHPwwbbWnhkDQmX4OixwBvuftRZtYJeM7Murr7J3VP\nHDZs2KbPM5kMmUwmTyGIpM+VV8KXvwy1fm2kDFRWVlJZWbnFX5dLD70XMMzdK7KPrwDc3UfWOucp\nYIS7v5Z9PBEY4u7T6ryXeugiORo3Di65JOyi2Lp17Ggkpnz20KcCXzezjmbWHOgHjK9zzkLge9lv\n3BboDLy7ZSGLyOfmz4cBA8JccyVzyVWjLRd332BmA4EJhP8B3OPuVWY2ILzso4HrgP9vZjOzX3a5\nu39QsKhFUmzdurA3yzXXwKGHxo5GkkQrRUVKzGWXwdy5oeWiZf0CWikqkkgTJsDYseGGFUrmsqWU\n0EVKxMqVcNZZ8MADsNtusaORJFLLRaQEuMNJJ0GXLnDDDbGjkVKjlotIgtx3H/zjH2FWi8jWUoUu\nEtmiRXDwwdqnRRqWz3noIlIgGzeGvvmllyqZy7ZTQheJaNQo+PTTMFVRZFup5SISyaJF4TZyr7wS\nBkNFGqKWi0gJcw9L+wcPVjKX/FFCF4nggQdg+XK4/PLYkUiaqOUiUmQrV8IBB8Azz4SWi0hjcm25\nKKGLFNkZZ0DbtnDTTbEjkaTQwiKREjRxIrz8MsyaFTsSSSP10EWKZM0aOP98uP32cBcikXxTQhcp\nkhtugP33h+OPjx2JpJV66CJFMG8e9OoVtsXdc8/Y0UjSaB66SAkZPDisBlUyl0LSoKhIgT31FMyZ\nA489FjsSSTsldJECWrMGBg2Cu+6C5s1jRyNpp5aLSAHddBN06wZHHx07EikHGhQVKZClS8OWuNOm\nwV57xY5GkkwrRUUiO+MM6NABhg+PHYkknVaKikQ0aRK88ALMnh07Eikn6qGL5NnGjXDJJXD99VoR\nKsWlhC6SZ3/8I2zYEFouIsWkHrpIHn32Gey7Lzz4IBx+eOxoJC20UlQkgttug4MPVjKXOFShi+TJ\nP/8Zbif3+uvQuXPsaCRNNG1RpMguugjMQpUukk9K6CJFNHcuHHYYVFfDbrvFjkbSRj10kSK6+mr4\nxS+UzCUuVegi22jKFDj55LCj4pe+FDsaSSNV6CJF4A5DhsCwYUrmEp8Susg2ePZZeO89OPPM2JGI\nKKGLbLWNG+GKK8IS/2baFUlKQE4J3cwqzKzazOaY2ZAGzsmY2Vtm9nczezG/YYqUnrFjYYcd4KST\nYkciEjQ6KGpmTYA5QG9gGTAV6Ofu1bXO2QV4HTja3Zea2W7uvqqe99KgqKRCTU1YRPT738ORR8aO\nRtIun4OiPYG57r7Q3WuAscCJdc45DXjM3ZcC1JfMRdLk3nvDTSuUzKWU5NL5awcsrvV4CSHJ19YZ\n2C7bavkycJu7P5CfEEVKy2efwbXXwrhxsSMR+Xf5GsppBnQHjgJ2Av5mZn9z93l5en+RknHHHXDo\noXDIIbEjEfl3uST0pUCHWo/bZ5+rbQmwyt3XAGvM7GWgG/CFhD5s2LBNn2cyGTKZzJZFLBLRxx/D\njTdCZWXsSCTNKisrqdyKf2S5DIo2BWYTBkWXA1OA/u5eVeucfYHfARXA9sBk4FR3f6fOe2lQVBLt\n2mvDitAH1FCUIsrbPUXdfYOZDQQmEAZR73H3KjMbEF720e5ebWbPAjOBDcDouslcJOk++ABuvTXc\nL1SkFGkvF5EcXX01rFwZpiqKFJO2zxXJo5Urw7zzt96CDh0aP18kn7Q5l0gejRwJ/fsrmUtpU4Uu\n0ojly2G//eDvf4c99ogdjZQjtVxE8mTQIGjaFG6+OXYkUq6U0EXyYMkS6NoVqqqgbdvY0Ui5Ug9d\nJA9GjICf/UzJXJJBFbpIAxYtgoMOCjd+btMmdjRSzlShi2yj66+Hc89VMpfkUIUuUo+FC6F797DM\nv3Xr2NFIuVOFLrINhg+H885TMpdkUYUuUseCBWFr3DlzoFWr2NGIqEIX2WrDh8P55yuZS/KoQhep\nZcEC6NED5s5VQpfSoQpdZCsMHw4XXqhkLsmUr1vQiSTeu+/C44+H3rlIEqlCF8m6/nq44AJV55Jc\nqtBFUHUu6aAKXYTQO1d1LkmnWS5S9t59N8w718wWKVWa5SKSI81skbRQhS5lTdW5JIEqdJEcqDqX\nNFGFLmVL1bkkhSp0kUaoOpe00Tx0KUvz58MTT4TqXCQtVKFLWbruulCd77pr7EhE8kcVupSdefPg\nySfDR5E0UYUuZee66+Cii6Bly9iRiOSXKnQpK3Pnwl/+oupc0kkVupSVa6+Fiy+GXXaJHYlI/mke\nupSN6mr47ndDdb7zzrGjEcmd5qGL1PFf/wWDByuZS3qpQpeyMGsWHHVUqM5btIgdjciWUYUuUsuv\nfw2/+IWSuaSbKnRJvZkz4ZhjQnW+006xoxHZcqrQRbJ+9Su4/HIlc0m/nBK6mVWYWbWZzTGzIZs5\n7xAzqzGzk/MXosjWmzoVpk2D88+PHYlI4TWa0M2sCXA7cAywH9DfzPZt4LwbgGfzHaTI1rrmGvjl\nL2GHHWJHIlJ4uVToPYG57r7Q3WuAscCJ9Zx3EfAosDKP8YlstVdegdmz4ac/jR2JSHHkktDbAYtr\nPV6SfW4TM9sDOMnd7wIabdyLFJp7qM6HDoXmzWNHI1Ic+RoU/S1Qu7eupC5RPfccLF8O//mfsSMR\nKZ5cNudaCnSo9bh99rnaegBjzcyA3YBjzazG3cfXfbNhw4Zt+jyTyZDJZLYwZJHNc4errgq7KjbT\n9nOSQJWVlVRWVm7x1zU6D93MmgKzgd7AcmAK0N/dqxo4fwzwpLv/uZ7XNA9dCu6xx8Lt5aZNgyaa\nmCspkOs89EbrF3ffYGYDgQmEFs097l5lZgPCyz667pdsVcQiebB+fZjVcsstSuZSfrRSVFJlzJhw\nvPQSmEZyJCVyrdCV0CU11qyBb3wDHnoIvvOd2NGI5I+W/kvZuesu6NZNyVzKlyp0SYXVq2GffeCF\nF2D//WNHI5JfqtClrNx4I/zgB0rmUt5UoUviLVsGBxwA06fDnnvGjkYk/zQoKmXj3HOhZctQpYuk\nUd7moYuUslmz4PHHwyZcIuVOPXRJtMsvh6uvhl13jR2JSHyq0CWxnn8+VObjxsWORKQ0qEKXRNqw\nIdz0eeRIbY8r8jkldEmk++8P9wg9WTc7FNlEs1wkcf71L9h339Bq6dkzdjQihaeFRZJaN9wAvXsr\nmYvUpQpdEmXBAjjkEJgxA9q1a/x8kTRQhS6pdPnlMGiQkrlIfTRtURLjpZdgypQwICoiX6QKXRKh\npgYGDoSbb4Ydd4wdjUhpUkKXRLjjDth9d01TFNkcDYpKyXvvvbAt7quvhumKIuVGuy1KavzkJ9C2\nrXZTlPKl3RYlFV5+GSZOhKqq2JGIlD710KVkrVsH550Ht90GLVrEjkak9CmhS8n6zW+gUyfo2zd2\nJCLJoB66lKT58+HQQ+GNN6Bjx9jRiMSllaKSWO5w/vkwZIiSuciWUEKXknPffbBqFVxySexIRJJF\nLRcpKcuXQ7duMGECHHhg7GhESoPmoUsinXJKWDw0fHjsSERKh+ahS+I8+ii88w489FDsSESSSRW6\nlIQVK0KrZdw4OOyw2NGIlBa1XCQx3MNc8y5dYMSI2NGIlB61XCQx7r8/3Ino4YdjRyKSbKrQJapF\ni6BHD3juudByEZEv0sIiKXkbNsAZZ8CllyqZi+SDErpEM2IENG0Kl10WOxKRdFAPXaL429/g9tvD\nXi1Nm8aORiQdcqrQzazCzKrNbI6ZDann9dPMbEb2eNXMDsh/qJIWH30Ep58Od98N7drFjkYkPRod\nFDWzJsAcoDewDJgK9HP36lrn9AKq3H21mVUAw9y9Vz3vpUHRMuce7gvavj387nexoxFJhnxOW+wJ\nzHX3hdk3HgucCGxK6O4+qdb5kwDVXVKvm2+GZctg7NjYkYikTy4JvR2wuNbjJYQk35CfAc9sS1CS\nTq++Gu4LOmUKbL997GhE0ievg6JmdiRwFvCdhs4ZNmzYps8zmQyZTCafIUiJWr4c+veHMWO0x7lI\nYyorK6msrNzir8ulh96L0BOvyD6+AnB3H1nnvK7AY0CFu89v4L3UQy9Da9fCkUdCRQX86lexoxFJ\nnrzt5WJmTYHZhEHR5cAUoL+7V9U6pwMwETijTj+97nspoZcZdzjnnDCz5ZFHoIlWPohssbwNirr7\nBjMbCEwgTHO8x92rzGxAeNlHA9cArYA7zcyAGnffXJ9dysTtt4ee+euvK5mLFJr2cpGCefppOPvs\nkMz32it2NCLJpd0WJaq33oKf/ASefFLJXKRY9Eew5N3ixXD88TBqFPT6wvIyESkUJXTJq/ffD7NZ\nBg8O9wcVkeJRD13y5pNPoHdvyGRg5MhGTxeRHOkWdFJUa9fCD34QFg39/vdgjf7TE5FcKaFL0axb\nBz/6EWy3XdijpZmG2kXySncskqKoqYFTTw0V+R/+oGQuEpN+/WSr1dRAv37hVnKPPgrNm8eOSKS8\nqUKXrfLZZ9C3L6xfD3/6k5K5SClQQpct9vHHcOyx0LJlqMy1Fa5IaVBCly2yYkWYmtilC9x/fxgI\nFZHSoIQuOauuhsMOg+OOgzvv1GZbIqVGg6KSk5dfDlMTR46EM8+MHY2I1Ec1ljTq7rvhhz+EBx9U\nMhcpZarQpUHr1sHFF4fq/LXXYJ99YkckIpujCl3qtXAhHHEEvPceTJqkZC6SBEro8gXjx0PPnmG3\nxD//GXbeOXZEIpILtVxkk08/hSFDwk0pHn88zGgRkeRQhS5AaKscdBCsXg0zZiiZiySRKvQy9+mn\nMHQoPPBAuKHzj34UOyIR2Vqq0MvYs8/CAQfAsmXw9ttK5iJJpwq9DC1YAD//OUyfDnfcEfZlEZHk\nU4VeRlavhquvhh494OCD4Z13lMxF0kQJvQysXQu33AKdO4f2yvTpIbHvsEPsyEQkn9RySbE1a8L9\nPUeODDNYJk6E/fePHZWIFIoSegp99BGMHg233hraK48/Hj6KSLqp5ZIi8+bB4MGw994wcyb85S/w\nxBNK5iLlQgk94WpqQtKuqIBvfSvccGLGjLAz4oEHxo5ORIpJLZcEcg/zxu+7Dx56CL7+dRgwILRW\nNNApUr6U0BOkujrckHnsWPjkEzj99LC1befOsSMTkVJg7l68b2bmxfx+Sbd+PUyeDE89BePGhSR+\n8snQvz/06gVmsSMUkWIwM9y90d94JfQSs2BBmF74/PPw3HOw557Qpw/07RsGN5XERcqPEnoCbNwI\ns2eHuwG9/DK88gr8z/9A797hqKiAdu1iRykisSmhlxj3cBegN9+EN96AadNgyhTYddcwO+Xww8PR\npYuqcBH5d0rokbjDihVQVRX2Spk1K8xIeftt+NKXwh4qnx+HHgpf+UrsiEWk1OU1oZtZBfBbwrz1\ne9x9ZD3n3AYcC3wKnOnu0+s5JxUJfd06WLwY/vGPcLz7LsyfHxb2zJkDzZuHSvub3wwfu3YN29S2\naRM7chFJorwldDNrAswBegPLgKlAP3evrnXOscBAdz/OzA4FbnX3XvW8V0kn9DVr4J//hJUrw82R\nV6yA5cvDsWwZLFkSEvn778Mee8DXvgYdO0KnTuFYvbqSfv0ytGoV+0oKo7KykkwmEzuMgknz9aX5\n2iD915drQs9lHnpPYK67L8y+8VjgRKC61jknAvcDuPtkM9vFzNq6+4otDz0/Vq0KFfPHH4dtYz8/\nPvoIPvgAPvwwfHz//XCsWhUSeps24fjqV6Ft2/DxG9+ATAbatw+zTtq2hWb1/JcbNqySVq0yxb7U\nokn7L02ary/N1wbpv75c5ZLQ2wGLaz1eQkjymztnafa5aAn9pZfgN78Jd6zfeWdo2RJ22SUcXbpA\nq1ZhQLJ16/87dtlFA5IiklypXSl6yinhEBEpF7n00HsBw9y9Ivv4CsBrD4ya2SjgRXd/OPu4Gjii\nbsvFzEq3gS4iUsLy1UOfCnzdzDoCy4F+QP8654wHLgQezv4P4KP6+ue5BCQiIlun0YTu7hvMbCAw\ngf+btlhlZgPCyz7a3Z82sz5mNo8wbfGswoYtIiJ1FXVhkYiIFE6UG1yY2UVmVmVmb5vZDTFiKDQz\n+7mZbTSzVM1KN7Mbsz+76Wb2mJntHDumbWVmFWZWbWZzzGxI7Hjyyczam9kLZjYr+/t2ceyY8s3M\nmpjZm2Y2PnYshZCdBv6n7O/drOxan3oVPaGbWQY4HjjA3Q8Abip2DIVmZu2B7wMLY8dSABOA/dz9\nQGAucGXkeLZJduHc7cAxwH5AfzPbN25UebUeuNTd9wMOAy5M2fUBDALeiR1EAd0KPO3uXYBuQFVD\nJ8ao0M8HbnD39QDuvipCDIV2C3BZ7CAKwd2fd/eN2YeTgPYx48mDTQvn3L0G+HzhXCq4+3ufb8Ph\n7p8QkkFq9vDMFk99gP8XO5ZCyP4FfLi7jwFw9/Xu/nFD58dI6J2B75rZJDN70cxSdQtjMzsBWOzu\nb8eOpQh+CjwTO4htVN/CudQkvNrM7GvAgcDkuJHk1efFU1oHA/cCVpnZmGxbabSZ7djQyQVZWGRm\nzwFtaz9F+A/+y+z33NXde5nZIcAjwN6FiKNQGrm+qwjtltqvJcpmru9qd38ye87VQI27/yFCiLKF\nzOzLwKPAoGylnnhmdhywwt2nZ1u5iftdy0EzoDtwobtPM7PfAlcAQxs6Oe/c/fsNvWZm5wF/zp43\nNTtw2Nrd3y9ELIXQ0PWZ2f7A14AZZmaEdsQbZtbT3VcWMcRtsrmfH4CZnUn4M/eoogRUWEuBDrUe\nt88+lxpm1oyQzB9w9ydix5NH3wZOMLM+wI5ACzO7391/HDmufFpC+It/Wvbxo0CDA/cxWi6Pk00E\nZtYZ2C5JyXxz3P3v7r67u+/t7nsRfhgHJSmZNya7lfJlwAnuvjZ2PHmwaeGcmTUnLJxL22yJe4F3\n3P3W2IHkk7tf5e4d3H1vws/thZQlc7ILNBdncyWEXW8bHACOsZfLGOBeM3sbWAuk6gdQh5O+PwN/\nBzQHngt/hDDJ3S+IG9LWa2jhXOSw8sbMvg2cDrxtZm8R/k1e5e5/jRuZbIGLgYfMbDvgXTazcFML\ni0REUiLKwiIREck/JXQRkZRQQhcRSQkldBGRlFBCFxFJCSV0EZGUUEIXEUkJJXQRkZT4X8kNBsUf\nAtCWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8fcf22ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html\n",
    "\n",
    "Preprocessing: The original Adult data set has 14 features, among which six are continuous and eight are categorical. In this data set, continuous features are discretized into quantiles, and each quantile is represented by a binary feature. Also, a categorical feature with m categories is converted to m binary features. Details on how each feature is converted can be found in the beginning of each file from this page. [JP98a]\n",
    "```\n",
    "# of classes: 2\n",
    "# of data: 1,605 / 30,956 (testing)\n",
    "# of features: 123 / 123 (testing)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/2/a1a') as f:\n",
    "    train_raw = f.readlines()\n",
    "\n",
    "with open('data/2/a1a.t') as f:\n",
    "    test_raw = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-1 3:1 11:1 14:1 19:1 39:1 42:1 55:1 64:1 67:1 73:1 75:1 76:1 80:1 83:1 \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw[0].split()[1:][0].split(':', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(raw_data):\n",
    "    num_examples = len(raw_data)\n",
    "    x = np.zeros((num_examples, num_features))\n",
    "    y = np.zeros((num_examples,))\n",
    "    for i, line in enumerate(raw_data):\n",
    "        tokens = line.split()\n",
    "        y[i] = (int(tokens[0]) + 1) / 2\n",
    "        for t in tokens[1:]:\n",
    "            findex, _ = t.split(':', 1)\n",
    "            findex = int(findex) - 1\n",
    "            x[i, findex] = 1\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, y_train = process_data(train_raw)\n",
    "x_test, y_test = process_data(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1605, 123), (1605,), (30956, 123), (30956,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24610591900311526, 0.24053495283628376)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train) / len(y_train), np.sum(y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_data = split_data(x_train, y_train, batch_size, shuffle=True)\n",
    "test_data = split_data(x_test, y_test, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(w, b, x):\n",
    "    return logistic(np.dot(x, np.squeeze(w)) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood(yhat, y):\n",
    "    return - np.nansum(y * np.log(yhat) + (1 - y) * np.log(1 - yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objective function $G(w, b)$:\n",
    "\n",
    "$$- \\sum_i {y_i log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\hat{y} = \\frac{1}{1 + \\exp(- (wx + b))}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient of $G(w, b)$:\n",
    "\n",
    "$$\n",
    "\\frac{dG}{dw} = - \\sum_i {\\frac{ D ( y_i log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) ) }{dw}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# D(yhat) / dw\n",
    "# = D((1 + exp(-wx - b))^-1) / dw\n",
    "# = -1 * (1 + exp(-wx - b))^-2 * D((1 + exp(-wx - b))) / dw\n",
    "# = - (1 + exp(-wx - b))^-2 * D(exp(-wx - b)) / dw\n",
    "# = - (1 + exp(-wx - b))^-2 * exp(-wx - b) * D(-wx - b) / dw\n",
    "# = (1 + exp(-wx - b))^-2 * exp(-wx - b) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# D(yhat) / b\n",
    "# = D((1 + exp(-wx - b))^-1) / db\n",
    "# = - (1 + exp(-wx - b))^-2 * exp(-wx - b) * D(-wx - b) / db\n",
    "# = (1 + exp(-wx - b))^-2 * exp(-wx - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# D(y log(yhat)) / dw\n",
    "# = y * D(log(yhat)) / dw\n",
    "# = y * 1 / yhat * D(yhat) / dw\n",
    "# = y / yhat * D(yhat) / dw\n",
    "\n",
    "# D(y log(yhat)) / db\n",
    "# = y / yhat * D(yhat) / db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# D((1 - y) log(1 - yhat)) / dw\n",
    "# = (1 - y) D(log(1 - yhat)) / dw\n",
    "# = (1 - y) * 1 / (1 - yhat) * (-D(yhat) / dw)\n",
    "# = - (1 - y) / (1 - yhat) * D(yhat) / dw\n",
    "\n",
    "# D((1 - y) log(1 - yhat)) / db\n",
    "# = - (1 - y) / (1 - yhat) * D(yhat) / db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dyhat_db(w, b, x):\n",
    "    # (1 + exp(-wx - b))^-2 * exp(-wx - b)\n",
    "    exp_wx_b = np.exp(-np.dot(x, w) - b)\n",
    "    return (1 + exp_wx_b)**(-2) * exp_wx_b\n",
    "\n",
    "def dyhat_dw(w, b, x):\n",
    "    # (1 + exp(-wx - b))^-2 * exp(-wx - b) * x\n",
    "    dy_db = dyhat_db(w, b, x)\n",
    "    return dy_db[:, np.newaxis] * x\n",
    "\n",
    "def gradient(w, b, x, y):\n",
    "    yhat = logistic_regression(w, b, x)\n",
    "    y_yhat = y / yhat\n",
    "    y1_yhat1 = -(1 - y) / (1 - yhat)\n",
    "    # D(yhat) / db\n",
    "    dy_dw = dyhat_dw(w, b, x)\n",
    "    # D(yhat) / dw\n",
    "    dy_db = dyhat_db(w, b, x)\n",
    "    #print(dy_dw.shape, dy_db.shape)\n",
    "    # D(y log(yhat)) / dw\n",
    "    dylogy_dw = y_yhat[:, np.newaxis] * dy_dw\n",
    "    # D(y log(yhat)) / db\n",
    "    dylogy_db = y_yhat * dy_db\n",
    "    # D((1 - y) log(1 - yhat)) / dw\n",
    "    d1ylog1y_dw = y1_yhat1[:, np.newaxis] * dy_dw\n",
    "    # D((1 - y) log(1 - yhat)) / db\n",
    "    d1ylog1y_db = y1_yhat1 * dy_db\n",
    "    # dG / dw\n",
    "    dG_dw = -np.sum(dylogy_dw + d1ylog1y_dw, axis=0)\n",
    "    # dG / db\n",
    "    #print(dylogy_db, d1ylog1y_db)\n",
    "    dG_db = -np.sum(dylogy_db + d1ylog1y_db, axis=0)\n",
    "    #print(dG_dw.shape, dG_db.shape)\n",
    "    return dG_dw, dG_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd_update(w, b, x, y, rate):\n",
    "    grad_w, grad_b = gradient(w, b, x, y)\n",
    "#     print(grad_w)\n",
    "#     print(grad_b)\n",
    "    w[:] = w - rate * grad_w\n",
    "    b[:] = b - rate * grad_b\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = np.random.randn(num_features)\n",
    "b = np.random.randn(1)\n",
    "# print(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2423.6891237\n",
      "1395.74603001\n",
      "1223.1204199\n",
      "1118.88477438\n",
      "1041.84996065\n",
      "982.932547815\n",
      "936.761476291\n",
      "899.7232083\n",
      "869.354439211\n",
      "843.957624719\n",
      "822.345908958\n",
      "803.675469581\n",
      "787.335531081\n",
      "772.875853782\n",
      "759.958492145\n",
      "748.325320278\n",
      "737.775875082\n",
      "728.152018408\n",
      "719.327160125\n",
      "711.198572704\n",
      "703.681831126\n",
      "696.706734935\n",
      "690.214278481\n",
      "684.154372427\n",
      "678.484110431\n",
      "673.166436065\n",
      "668.169106688\n",
      "663.463879857\n",
      "659.025868047\n",
      "654.833021831\n",
      "650.86571195\n",
      "647.106388169\n",
      "643.539298272\n",
      "640.15025457\n",
      "636.926438257\n",
      "633.856234212\n",
      "630.929090463\n",
      "628.135397844\n",
      "625.46638628\n",
      "622.914034922\n",
      "620.470993863\n",
      "618.13051564\n",
      "615.88639505\n",
      "613.73291607\n",
      "611.664804887\n",
      "609.67718822\n",
      "607.76555622\n",
      "605.925729377\n",
      "604.153828937\n",
      "602.446250392\n",
      "600.799639685\n",
      "599.210871817\n",
      "597.677031574\n",
      "596.195396148\n",
      "594.763419425\n",
      "593.378717784\n",
      "592.039057218\n",
      "590.742341659\n",
      "589.486602372\n",
      "588.269988307\n",
      "587.090757312\n",
      "585.947268124\n",
      "584.837973061\n",
      "583.761411335\n",
      "582.716202944\n",
      "581.701043065\n",
      "580.714696924\n",
      "579.755995075\n",
      "578.82382907\n",
      "577.917147471\n",
      "577.034952172\n",
      "576.176295015\n",
      "575.34027466\n",
      "574.526033695\n",
      "573.732755964\n",
      "572.959664089\n",
      "572.206017174\n",
      "571.471108675\n",
      "570.754264423\n",
      "570.054840781\n",
      "569.372222935\n",
      "568.705823296\n",
      "568.055080012\n",
      "567.419455583\n",
      "566.798435561\n",
      "566.191527336\n",
      "565.598259004\n",
      "565.018178304\n",
      "564.450851616\n",
      "563.895863031\n",
      "563.352813471\n",
      "562.821319864\n",
      "562.301014366\n",
      "561.791543632\n",
      "561.292568126\n",
      "560.803761476\n",
      "560.324809856\n",
      "559.855411413\n",
      "559.395275719\n",
      "558.944123255\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    cumulative_lld = 0\n",
    "    for bx, by in train_data:\n",
    "        yhat = logistic_regression(w, b, bx)\n",
    "        lld = log_likelihood(yhat, by)\n",
    "        cumulative_lld += lld\n",
    "        sgd_update(w, b, bx, by, learning_rate)\n",
    "#         print(w, b)\n",
    "    print(cumulative_lld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835443855795\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0.0\n",
    "num_total = len(y_test)\n",
    "for tx, ty in test_data:\n",
    "    yhat = logistic_regression(w, b, tx)\n",
    "    prediction = (np.sign(yhat - 0.5) + 1) / 2\n",
    "    num_correct += np.sum(prediction == ty)\n",
    "print(num_correct / num_total)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
